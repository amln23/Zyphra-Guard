{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF_lMYhYf1oW",
        "outputId": "474e6dfc-d9f8-4465-f9c1-84a0357bf9df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting data processing with corrected script...\n",
            "Loading 02-14-2018.csv...\n",
            "Loading 02-16-2018.csv...\n",
            "Loading 02-21-2018.csv...\n",
            "Total rows before cleaning: 1647602\n",
            "Total rows after cleaning and NaN fill: 1273816. Applying aggressive sampling...\n",
            "Total rows after aggressive sampling: 300000\n",
            "Generating synthetic web features for 150000 attacks and 150000 benign flows...\n",
            "\n",
            "Successfully created dataset_unified.csv with 300000 rows.\n",
            "Final features exported: 42 columns (41 features + Label)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "DATA_FILES = ['02-14-2018.csv', '02-16-2018.csv', '02-21-2018.csv']\n",
        "OUTPUT_FILE = 'dataset_unified.csv'\n",
        "RANDOM_STATE = 42\n",
        "SAMPLE_SIZE_PER_CLASS = 150000\n",
        "\n",
        "\n",
        "feature_index_content = {\n",
        "  \"feature_order\": [\n",
        "    \"url_length\", \"num_dots\", \"num_slashes\", \"num_hyphens\", \"num_parameters\",\n",
        "    \"suspicious_tokens_count\", \"has_ip_address\", \"entropy\", \"tld_length\",\n",
        "    \"domain_length\", \"path_length\", \"query_length\", \"is_https\",\n",
        "    \"js_total_functions\", \"js_eval_count\", \"js_settimeout_count\",\n",
        "    \"js_setinterval_count\", \"js_function_length_avg\", \"script_count\",\n",
        "    \"script_external_count\", \"img_count\", \"iframe_count\", \"anchor_count\",\n",
        "    \"form_count\", \"input_count\", \"button_count\", \"css_count\",\n",
        "    \"dom_total_nodes\", \"dom_mutation_rate\", \"dom_depth\", \"text_length\",\n",
        "    \"has_login_keyword\", \"has_verify_keyword\", \"has_bank_keyword\",\n",
        "    \"has_pay_keyword\", \"has_wallet_keyword\", \"if_window_open\",\n",
        "    \"if_fetch_intercept\", \"if_cookie_access\", \"if_localstorage_access\",\n",
        "    \"if_clipboard_access\"\n",
        "  ]\n",
        "}\n",
        "FULL_FEATURE_ORDER = feature_index_content[\"feature_order\"]\n",
        "\n",
        "SYNTHETIC_WEB_FEATURES = [\n",
        "    'url_length', 'query_length', 'entropy_query', 'has_single_quote',\n",
        "    'has_script_tag', 'content_length', 'is_post_method', 'num_dots'\n",
        "]\n",
        "\n",
        "print(\"Starting data processing with corrected script...\")\n",
        "\n",
        "\n",
        "dfs = []\n",
        "for f in DATA_FILES:\n",
        "    if os.path.exists(f):\n",
        "        print(f\"Loading {f}...\")\n",
        "        dfs.append(pd.read_csv(f, low_memory=False))\n",
        "    else:\n",
        "        print(f\"Error: CICIDS data file {f} not found. Ensure all 3 files are in the working directory.\")\n",
        "    \n",
        "\n",
        "if not dfs:\n",
        "    raise SystemExit('No CICIDS data files loaded. Please check file paths.')\n",
        "\n",
        "df = pd.concat(dfs, ignore_index=True)\n",
        "del dfs\n",
        "print(f\"Total rows before cleaning: {len(df)}\")\n",
        "\n",
        "\n",
        "def clean_column_name(col):\n",
        "    col = col.strip()\n",
        "    col = re.sub(r'\\s+', ' ', col)\n",
        "    return col.lower()\n",
        "\n",
        "df.columns = [clean_column_name(col) for col in df.columns]\n",
        "\n",
        "\n",
        "df.drop_duplicates(inplace=True)\n",
        "COLS_TO_CONVERT = [col for col in df.columns if col not in ['label'] and df[col].dtype == 'object']\n",
        "for col in COLS_TO_CONVERT:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "def unify_label(x):\n",
        "    s = str(x).lower()\n",
        "    if 'benign' in s or s.strip() == '0':\n",
        "        return 0\n",
        "    return 1\n",
        "df['Label'] = df['label'].apply(unify_label)\n",
        "df.drop(columns=['label'], inplace=True, errors='ignore')\n",
        "\n",
        "print(f\"Total rows after cleaning and NaN fill: {len(df)}. Applying aggressive sampling...\")\n",
        "\n",
        "df_benign = df[df['Label'] == 0].copy()\n",
        "df_attack = df[df['Label'] == 1].copy()\n",
        "del df\n",
        "\n",
        "if len(df_benign) > SAMPLE_SIZE_PER_CLASS:\n",
        "    df_benign = df_benign.sample(n=SAMPLE_SIZE_PER_CLASS, random_state=RANDOM_STATE).copy()\n",
        "\n",
        "if len(df_attack) > SAMPLE_SIZE_PER_CLASS:\n",
        "    df_attack = df_attack.sample(n=SAMPLE_SIZE_PER_CLASS, random_state=RANDOM_STATE).copy()\n",
        "\n",
        "df = pd.concat([df_benign, df_attack], ignore_index=True).copy()\n",
        "del df_benign, df_attack\n",
        "\n",
        "print(f\"Total rows after aggressive sampling: {len(df)}\")\n",
        "if len(df) == 0:\n",
        "    raise SystemExit(\"Fatal Error: DataFrame is empty after sampling. Check data quality.\")\n",
        "\n",
        "N_attack = df['Label'].sum()\n",
        "N_benign = len(df) - N_attack\n",
        "synthetic_data = np.zeros((len(df), len(SYNTHETIC_WEB_FEATURES)))\n",
        "is_attack = df['Label'].values == 1\n",
        "is_benign = df['Label'].values == 0\n",
        "\n",
        "print(f\"Generating synthetic web features for {N_attack} attacks and {N_benign} benign flows...\")\n",
        "\n",
        "# CONTENT_LENGTH - index 5\n",
        "content_signal_col = 'totlen fwd pkts'\n",
        "if content_signal_col in df.columns and 'tot fwd pkts' in df.columns:\n",
        "    fwd_pkts_safe = df['tot fwd pkts'].values.copy()\n",
        "    fwd_pkts_safe[fwd_pkts_safe == 0] = 1\n",
        "    content_signal = df[content_signal_col].values / fwd_pkts_safe\n",
        "    synthetic_data[:, 5] = np.clip(content_signal, 0, 1000)\n",
        "else:\n",
        "    synthetic_data[:, 5] = np.random.randint(50, 500, len(df))\n",
        "\n",
        "# IS_POST_METHOD - index 6\n",
        "post_signal_col_1 = 'tot fwd pkts'\n",
        "post_signal_col_2 = 'tot bwd pkts'\n",
        "if post_signal_col_1 in df.columns and post_signal_col_2 in df.columns:\n",
        "    post_signal = (df[post_signal_col_1].values > df[post_signal_col_2].values * 1.5)\n",
        "    synthetic_data[:, 6] = np.where(post_signal, 1, 0)\n",
        "    synthetic_data[:, 6][is_attack] = np.random.choice([1, 0], N_attack, p=[0.5, 0.5])\n",
        "else:\n",
        "    synthetic_data[:, 6] = np.random.choice([1, 0], len(df), p=[0.2, 0.8])\n",
        "\n",
        "synthetic_data[:, 0][is_benign] = np.random.randint(40, 100, N_benign)\n",
        "synthetic_data[:, 0][is_attack] = np.random.randint(90, 250, N_attack)\n",
        "synthetic_data[:, 1][is_benign] = np.random.randint(0, 5, N_benign)\n",
        "synthetic_data[:, 1][is_attack] = np.random.randint(15, 60, N_attack)\n",
        "synthetic_data[:, 2][is_benign] = np.random.uniform(1.0, 3.0, N_benign)\n",
        "synthetic_data[:, 2][is_attack] = np.random.uniform(3.5, 5.5, N_attack)\n",
        "synthetic_data[:, 3][is_attack] = np.random.choice([1, 0], N_attack, p=[0.6, 0.4])\n",
        "synthetic_data[:, 3][is_benign] = 0\n",
        "synthetic_data[:, 4][is_attack] = np.random.choice([1, 0], N_attack, p=[0.4, 0.6])\n",
        "synthetic_data[:, 4][is_benign] = 0\n",
        "synthetic_data[:, 7] = np.random.randint(1, 4, len(df))\n",
        "\n",
        "\n",
        "df_synth_features = pd.DataFrame(synthetic_data, columns=SYNTHETIC_WEB_FEATURES, index=df.index)\n",
        "df_core = df.drop(columns=SYNTHETIC_WEB_FEATURES, errors='ignore')\n",
        "df_unified = pd.concat([df_core, df_synth_features], axis=1)\n",
        "\n",
        "missing_features = [f for f in FULL_FEATURE_ORDER if f not in df_unified.columns]\n",
        "for feature in missing_features:\n",
        "    df_unified[feature] = 0\n",
        "\n",
        "final_columns_order = FULL_FEATURE_ORDER + ['Label']\n",
        "df_final = df_unified[final_columns_order].copy()\n",
        "\n",
        "df_final.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"\\nSuccessfully created {OUTPUT_FILE} with {len(df_final)} rows.\")\n",
        "print(f\"Final features exported: {df_final.shape[1]} columns (41 features + Label)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
